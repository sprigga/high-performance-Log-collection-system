"""
å£“åŠ›æ¸¬è©¦è…³æœ¬ - æ¨¡æ“¬ 100 å°è¨­å‚™ä½µç™¼ç™¼é€æ—¥èªŒ
"""
import asyncio
import aiohttp
import time
import random
from datetime import datetime
from typing import List

# ==========================================
# æ¸¬è©¦é…ç½®
# ==========================================
# BASE_URL = "http://localhost:8080"  # åŸå§‹ç«¯å£è¨­å®š
BASE_URL = "http://localhost:18723"  # Nginx ç«¯é»ï¼ˆå°æ‡‰ docker-compose.yml é…ç½®ï¼‰
NUM_DEVICES = 100                   # è¨­å‚™æ•¸é‡
LOGS_PER_DEVICE = 100               # æ¯å°è¨­å‚™ç™¼é€çš„æ—¥èªŒæ•¸
# CONCURRENT_LIMIT = 50               # åŸå§‹ä¸¦ç™¼é™åˆ¶
# CONCURRENT_LIMIT = 200              # ç¬¬ä¸€æ¬¡èª¿æ•´
# CONCURRENT_LIMIT = 500              # é€²ä¸€æ­¥æå‡ä¸¦ç™¼é™åˆ¶
# CONCURRENT_LIMIT = 100              # æ‰¹é‡æ¨¡å¼ä½¿ç”¨è¼ƒå°‘ä¸¦ç™¼ï¼ˆåŸè¨­å®šï¼‰
CONCURRENT_LIMIT = 200              # æé«˜ä¸¦ç™¼ä»¥é…åˆæ›´å°çš„æ‰¹æ¬¡
# BATCH_SIZE = 100                    # åŸå§‹æ‰¹æ¬¡å¤§å°ï¼ˆP95 ~316msï¼‰
BATCH_SIZE = 5                     # æ¸›å°æ‰¹æ¬¡å¤§å°ä»¥é™ä½ P95 å›æ‡‰æ™‚é–“
USE_BATCH_API = True                # æ˜¯å¦ä½¿ç”¨æ‰¹é‡ APIï¼ˆæ–°å¢ï¼‰

LOG_LEVELS = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
LOG_MESSAGES = [
    "ç³»çµ±æ­£å¸¸é‹è¡Œ",
    "è¨˜æ†¶é«”ä½¿ç”¨ç‡: {usage}%",
    "CPU æº«åº¦: {temp}Â°C",
    "ç¶²è·¯é€£ç·šç•°å¸¸",
    "è³‡æ–™åº«æŸ¥è©¢è¶…æ™‚",
    "æª”æ¡ˆè®€å–å¤±æ•—",
    "æ„Ÿæ¸¬å™¨è®€æ•¸ç•°å¸¸",
    "æ”å½±æ©Ÿç•«é¢æ¨¡ç³Š",
    "ç¡¬ç¢Ÿç©ºé–“ä¸è¶³",
    "è¨­å‚™é‡æ–°å•Ÿå‹•"
]

# ==========================================
# ç”Ÿæˆæ¸¬è©¦è³‡æ–™
# ==========================================
def generate_log_data(device_id: str, log_num: int) -> dict:
    """
    ç”Ÿæˆéš¨æ©Ÿæ—¥èªŒè³‡æ–™
    """
    log_level = random.choice(LOG_LEVELS)
    message_template = random.choice(LOG_MESSAGES)
    
    # æ ¹æ“šè¨Šæ¯æ¨¡æ¿å¡«å…¥è®Šæ•¸
    if "{usage}" in message_template:
        message = message_template.format(usage=random.randint(50, 95))
    elif "{temp}" in message_template:
        message = message_template.format(temp=random.randint(40, 85))
    else:
        message = message_template
    
    return {
        "device_id": device_id,
        "log_level": log_level,
        "message": f"{message} (#{log_num})",
        "log_data": {
            "test_id": log_num,
            "timestamp": datetime.now().isoformat(),
            "random_value": random.random(),
            "sequence": log_num
        }
    }

# ==========================================
# ç™¼é€å–®ç­†æ—¥èªŒ
# ==========================================
async def send_log(session: aiohttp.ClientSession, device_id: str, log_num: int) -> dict:
    """
    ç™¼é€å–®ç­†æ—¥èªŒåˆ° API

    è¿”å›ï¼š
        dict: {
            "success": bool,
            "response_time": float,
            "status": int,
            "error": str or None
        }
    """
    url = f"{BASE_URL}/api/log"
    log_data = generate_log_data(device_id, log_num)

    start_time = time.time()

    try:
        async with session.post(url, json=log_data, timeout=aiohttp.ClientTimeout(total=10)) as response:
            response_time = (time.time() - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’

            if response.status == 200:
                return {
                    "success": True,
                    "response_time": response_time,
                    "status": response.status,
                    "error": None,
                    "count": 1
                }
            else:
                return {
                    "success": False,
                    "response_time": response_time,
                    "status": response.status,
                    "error": await response.text(),
                    "count": 1
                }

    except asyncio.TimeoutError:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": "è«‹æ±‚è¶…æ™‚",
            "count": 1
        }
    except Exception as e:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": str(e),
            "count": 1
        }

# ==========================================
# ç™¼é€æ‰¹é‡æ—¥èªŒï¼ˆæ–°å¢é«˜æ•ˆèƒ½ç«¯é»ï¼‰
# ==========================================
async def send_batch_logs(session: aiohttp.ClientSession, logs: List[dict]) -> dict:
    """
    æ‰¹é‡ç™¼é€æ—¥èªŒåˆ° APIï¼ˆä½¿ç”¨æ‰¹é‡ç«¯é»ï¼‰

    è¿”å›ï¼š
        dict: {
            "success": bool,
            "response_time": float,
            "status": int,
            "error": str or None,
            "count": int
        }
    """
    url = f"{BASE_URL}/api/logs/batch"
    batch_data = {"logs": logs}

    start_time = time.time()

    try:
        async with session.post(url, json=batch_data, timeout=aiohttp.ClientTimeout(total=30)) as response:
            response_time = (time.time() - start_time) * 1000

            if response.status == 200:
                return {
                    "success": True,
                    "response_time": response_time,
                    "status": response.status,
                    "error": None,
                    "count": len(logs)
                }
            else:
                return {
                    "success": False,
                    "response_time": response_time,
                    "status": response.status,
                    "error": await response.text(),
                    "count": len(logs)
                }

    except asyncio.TimeoutError:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": "è«‹æ±‚è¶…æ™‚",
            "count": len(logs)
        }
    except Exception as e:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": str(e),
            "count": len(logs)
        }

# ==========================================
# æ‰¹æ¬¡ç™¼é€æ—¥èªŒ
# ==========================================
async def batch_send_logs(
    session: aiohttp.ClientSession,
    device_id: str,
    num_logs: int,
    semaphore: asyncio.Semaphore
) -> List[dict]:
    """
    æ‰¹æ¬¡ç™¼é€æ—¥èªŒï¼ˆä½¿ç”¨ä¿¡è™Ÿé‡æ§åˆ¶ä¸¦ç™¼ï¼‰
    """
    if USE_BATCH_API:
        # ä½¿ç”¨æ‰¹é‡ APIï¼ˆé«˜æ•ˆèƒ½æ¨¡å¼ï¼‰
        # å°‡æ—¥èªŒåˆ†æˆå¤šå€‹å°æ‰¹æ¬¡ç™¼é€
        all_logs = [generate_log_data(device_id, log_num) for log_num in range(num_logs)]
        results = []

        # æŒ‰ BATCH_SIZE åˆ†å‰²æˆå¤šå€‹æ‰¹æ¬¡
        for i in range(0, len(all_logs), BATCH_SIZE):
            batch = all_logs[i:i + BATCH_SIZE]
            async with semaphore:
                result = await send_batch_logs(session, batch)
                results.append(result)

        return results
    else:
        # åŸå§‹å–®ç­†ç™¼é€æ¨¡å¼
        async def send_with_semaphore(log_num: int) -> dict:
            async with semaphore:
                return await send_log(session, device_id, log_num)

        tasks = [send_with_semaphore(log_num) for log_num in range(num_logs)]
        return await asyncio.gather(*tasks)

# ==========================================
# ä¸»è¦å£“åŠ›æ¸¬è©¦
# ==========================================
async def stress_test(
    num_devices: int = NUM_DEVICES,
    logs_per_device: int = LOGS_PER_DEVICE,
    concurrent_limit: int = CONCURRENT_LIMIT
):
    """
    åŸ·è¡Œå£“åŠ›æ¸¬è©¦
    
    åƒæ•¸ï¼š
        num_devices: è¨­å‚™æ•¸é‡
        logs_per_device: æ¯å°è¨­å‚™ç™¼é€çš„æ—¥èªŒæ•¸
        concurrent_limit: ä¸¦ç™¼é™åˆ¶
    """
    print("=" * 70)
    print("  ğŸ“Š æ—¥èªŒæ”¶é›†ç³»çµ± - å£“åŠ›æ¸¬è©¦")
    print("=" * 70)
    print(f"æ¸¬è©¦é…ç½®ï¼š")
    print(f"  â€¢ è¨­å‚™æ•¸é‡: {num_devices}")
    print(f"  â€¢ æ¯å°è¨­å‚™æ—¥èªŒæ•¸: {logs_per_device}")
    print(f"  â€¢ ç¸½æ—¥èªŒæ•¸: {num_devices * logs_per_device:,}")
    print(f"  â€¢ ä¸¦ç™¼é™åˆ¶: {concurrent_limit}")
    print(f"  â€¢ API ç«¯é»: {BASE_URL}")
    print("-" * 70)
    
    # å»ºç«‹ä¿¡è™Ÿé‡æ§åˆ¶ä¸¦ç™¼
    semaphore = asyncio.Semaphore(concurrent_limit)
    
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = time.time()
    
    # å»ºç«‹ HTTP Session
    connector = aiohttp.TCPConnector(limit=concurrent_limit, limit_per_host=concurrent_limit)
    timeout = aiohttp.ClientTimeout(total=300)  # ç¸½è¶…æ™‚ 5 åˆ†é˜
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # ç‚ºæ¯å°è¨­å‚™å»ºç«‹ä»»å‹™
        device_tasks = []
        
        for device_num in range(num_devices):
            device_id = f"device_{device_num:03d}"
            task = batch_send_logs(session, device_id, logs_per_device, semaphore)
            device_tasks.append(task)
        
        print("â³ é–‹å§‹ç™¼é€æ—¥èªŒ...")
        
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        all_results = await asyncio.gather(*device_tasks)
    
    # è¨ˆç®—ç¸½è€—æ™‚
    total_time = time.time() - start_time
    
    # æ•´ç†çµæœ
    all_responses = [result for device_results in all_results for result in device_results]

    # çµ±è¨ˆè³‡æ–™ï¼ˆè€ƒæ…®æ‰¹é‡æ¨¡å¼ï¼‰
    total_requests = len(all_responses)
    successful_requests = sum(1 for r in all_responses if r["success"])
    failed_requests = total_requests - successful_requests
    # è¨ˆç®—å¯¦éš›æ—¥èªŒæ•¸é‡ï¼ˆæ‰¹é‡æ¨¡å¼ä¸‹ä¸€å€‹è«‹æ±‚åŒ…å«å¤šç­†æ—¥èªŒï¼‰
    total_logs_sent = sum(r.get("count", 1) for r in all_responses)
    successful_logs = sum(r.get("count", 1) for r in all_responses if r["success"])

    response_times = [r["response_time"] for r in all_responses if r["success"]]
    
    if response_times:
        avg_response_time = sum(response_times) / len(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)
        
        # è¨ˆç®—ç™¾åˆ†ä½æ•¸
        sorted_times = sorted(response_times)
        p50 = sorted_times[int(len(sorted_times) * 0.50)]
        p95 = sorted_times[int(len(sorted_times) * 0.95)]
        p99 = sorted_times[int(len(sorted_times) * 0.99)]
    else:
        avg_response_time = 0
        min_response_time = 0
        max_response_time = 0
        p50 = p95 = p99 = 0

    # ååé‡æŒ‰å¯¦éš›æ—¥èªŒæ•¸è¨ˆç®—ï¼ˆè€Œéè«‹æ±‚æ•¸ï¼‰
    throughput = successful_logs / total_time if total_time > 0 else 0

    # è¼¸å‡ºçµæœ
    print("\n" + "=" * 70)
    print("  ğŸ“ˆ æ¸¬è©¦çµæœ")
    print("=" * 70)

    print(f"\nâ±ï¸  æ™‚é–“çµ±è¨ˆï¼š")
    print(f"  â€¢ ç¸½è€—æ™‚: {total_time:.2f} ç§’")

    print(f"\nğŸ“Š è«‹æ±‚çµ±è¨ˆï¼š")
    if USE_BATCH_API:
        print(f"  â€¢ æ‰¹é‡è«‹æ±‚æ•¸: {total_requests:,}")
        print(f"  â€¢ ç¸½æ—¥èªŒæ•¸: {total_logs_sent:,}")
        print(f"  â€¢ æˆåŠŸæ—¥èªŒ: {successful_logs:,} ({successful_logs/total_logs_sent*100:.1f}%)")
    else:
        print(f"  â€¢ ç¸½è«‹æ±‚æ•¸: {total_requests:,}")
    print(f"  â€¢ æˆåŠŸè«‹æ±‚: {successful_requests:,} ({successful_requests/total_requests*100:.1f}%)")
    print(f"  â€¢ å¤±æ•—è«‹æ±‚: {failed_requests:,} ({failed_requests/total_requests*100:.1f}%)")
    
    print(f"\nâš¡ æ•ˆèƒ½æŒ‡æ¨™ï¼š")
    print(f"  â€¢ ååé‡: {throughput:.2f} logs/ç§’")
    print(f"  â€¢ å¹³å‡å›æ‡‰æ™‚é–“: {avg_response_time:.2f} ms")
    print(f"  â€¢ æœ€å°å›æ‡‰æ™‚é–“: {min_response_time:.2f} ms")
    print(f"  â€¢ æœ€å¤§å›æ‡‰æ™‚é–“: {max_response_time:.2f} ms")
    
    print(f"\nğŸ“‰ ç™¾åˆ†ä½æ•¸ï¼š")
    print(f"  â€¢ P50 (ä¸­ä½æ•¸): {p50:.2f} ms")
    print(f"  â€¢ P95: {p95:.2f} ms")
    print(f"  â€¢ P99: {p99:.2f} ms")
    
    # éŒ¯èª¤åˆ†æ
    if failed_requests > 0:
        print(f"\nâŒ éŒ¯èª¤åˆ†æï¼š")
        error_types = {}
        for r in all_responses:
            if not r["success"]:
                error = r["error"] or f"HTTP {r['status']}"
                error_types[error] = error_types.get(error, 0) + 1
        
        for error, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
            print(f"  â€¢ {error}: {count} æ¬¡")
    
    print("\n" + "=" * 70)
    
    # åˆ¤æ–·æ˜¯å¦é”åˆ°ç›®æ¨™
    target_throughput = 10000  # ç›®æ¨™ï¼š10,000 logs/ç§’
    target_p95 = 100           # ç›®æ¨™ï¼šP95 < 100ms
    
    print(f"\nğŸ¯ ç›®æ¨™é”æˆæƒ…æ³ï¼š")
    
    if throughput >= target_throughput:
        print(f"  âœ… ååé‡é”æ¨™: {throughput:.2f} >= {target_throughput} logs/ç§’")
    else:
        print(f"  âŒ ååé‡æœªé”æ¨™: {throughput:.2f} < {target_throughput} logs/ç§’")
    
    if p95 <= target_p95:
        print(f"  âœ… P95 å›æ‡‰æ™‚é–“é”æ¨™: {p95:.2f} <= {target_p95} ms")
    else:
        print(f"  âŒ P95 å›æ‡‰æ™‚é–“æœªé”æ¨™: {p95:.2f} > {target_p95} ms")
    
    if failed_requests == 0:
        print(f"  âœ… ç„¡å¤±æ•—è«‹æ±‚")
    else:
        print(f"  âš ï¸ æœ‰ {failed_requests} å€‹å¤±æ•—è«‹æ±‚")
    
    print("=" * 70)

# ==========================================
# æŸ¥è©¢æ¸¬è©¦
# ==========================================
async def query_test(device_id: str = "device_000"):
    """
    æ¸¬è©¦æŸ¥è©¢ API
    """
    print(f"\nğŸ“– æŸ¥è©¢æ¸¬è©¦: {device_id}")
    print("-" * 70)
    
    url = f"{BASE_URL}/api/logs/{device_id}?limit=10"
    
    start_time = time.time()
    
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            response_time = (time.time() - start_time) * 1000
            
            if response.status == 200:
                data = await response.json()
                print(f"âœ… æŸ¥è©¢æˆåŠŸ")
                print(f"  â€¢ å›æ‡‰æ™‚é–“: {response_time:.2f} ms")
                print(f"  â€¢ è³‡æ–™ä¾†æº: {data.get('source', 'unknown')}")
                print(f"  â€¢ æ—¥èªŒæ•¸é‡: {data.get('total', 0)}")
            else:
                print(f"âŒ æŸ¥è©¢å¤±æ•—: HTTP {response.status}")

# ==========================================
# ä¸»ç¨‹å¼
# ==========================================
async def main():
    """
    ä¸»ç¨‹å¼å…¥å£
    """
    # åŸ·è¡Œå£“åŠ›æ¸¬è©¦
    await stress_test(
        num_devices=NUM_DEVICES,
        logs_per_device=LOGS_PER_DEVICE,
        concurrent_limit=CONCURRENT_LIMIT
    )
    
    # ç­‰å¾… Worker è™•ç†å®Œæˆ
    print("\nâ³ ç­‰å¾… 5 ç§’è®“ Worker è™•ç†æ—¥èªŒ...")
    await asyncio.sleep(5)
    
    # åŸ·è¡ŒæŸ¥è©¢æ¸¬è©¦
    await query_test("device_000")
    
    # æŸ¥è©¢çµ±è¨ˆè³‡æ–™
    print(f"\nğŸ“Š æŸ¥è©¢ç³»çµ±çµ±è¨ˆ...")
    async with aiohttp.ClientSession() as session:
        async with session.get(f"{BASE_URL}/api/stats") as response:
            if response.status == 200:
                stats = await response.json()
                print(f"  â€¢ ç¸½æ—¥èªŒæ•¸: {stats.get('total_logs', 0):,}")
                print(f"  â€¢ æŒ‰ç­‰ç´šçµ±è¨ˆ:")
                for level, count in stats.get('logs_by_level', {}).items():
                    print(f"    - {level}: {count:,}")

if __name__ == "__main__":
    asyncio.run(main())
