"""
èƒŒæ™¯ Worker - å¾ Redis Stream æ¶ˆè²»æ—¥èªŒä¸¦æ‰¹æ¬¡å¯«å…¥ PostgreSQL
"""
import os
import json
import time
import signal
import sys
from datetime import datetime
from zoneinfo import ZoneInfo
import redis
from sqlalchemy import text
from database import SyncSessionLocal, sync_engine

# ==========================================
# é…ç½®
# ==========================================
REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
WORKER_NAME = os.getenv('WORKER_NAME', f'worker-{int(time.time())}')

STREAM_NAME = 'logs:stream'
GROUP_NAME = 'log_workers'
BATCH_SIZE = 100  # æ¯æ¬¡æ‰¹æ¬¡è™•ç† 100 ç­†
BLOCK_MS = 5000   # é˜»å¡ç­‰å¾… 5 ç§’

# å…¨åŸŸè®Šæ•¸
running = True
redis_client = None

# ==========================================
# è¨Šè™Ÿè™•ç†
# ==========================================
def signal_handler(sig, frame):
    """
    è™•ç† SIGINT å’Œ SIGTERM è¨Šè™Ÿï¼ˆå„ªé›…é—œé–‰ï¼‰
    """
    global running
    print(f"\nğŸ›‘ æ¥æ”¶åˆ°è¨Šè™Ÿ {sig}ï¼Œæº–å‚™é—œé–‰ Worker...")
    running = False

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ==========================================
# Redis é€£ç·š
# ==========================================
def init_redis():
    """
    åˆå§‹åŒ– Redis é€£ç·š
    """
    global redis_client

    try:
        redis_client = redis.Redis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            decode_responses=True,
            socket_connect_timeout=5,
            socket_keepalive=True,
            max_connections=10
        )

        # æ¸¬è©¦é€£ç·š
        redis_client.ping()
        print(f"âœ… Redis é€£ç·šæˆåŠŸ ({REDIS_HOST}:{REDIS_PORT})")

        # ç¢ºä¿æ¶ˆè²»è€…ç¾¤çµ„å­˜åœ¨
        try:
            redis_client.xgroup_create(
                name=STREAM_NAME,
                groupname=GROUP_NAME,
                id='0',
                mkstream=True
            )
            print(f"âœ… å»ºç«‹æ¶ˆè²»è€…ç¾¤çµ„: {GROUP_NAME}")
        except redis.exceptions.ResponseError as e:
            if "BUSYGROUP" in str(e):
                print(f"â„¹ï¸ æ¶ˆè²»è€…ç¾¤çµ„å·²å­˜åœ¨: {GROUP_NAME}")
            else:
                raise

        return True

    except Exception as e:
        print(f"âŒ Redis é€£ç·šå¤±æ•—: {e}")
        return False

# ==========================================
# æ‰¹æ¬¡å¯«å…¥ PostgreSQL
# ==========================================
def batch_insert_logs(logs_data):
    """
    æ‰¹æ¬¡æ’å…¥æ—¥èªŒåˆ° PostgreSQL

    åƒæ•¸ï¼š
        logs_data: list of dictï¼ŒåŒ…å«æ—¥èªŒè³‡æ–™

    è¿”å›ï¼š
        bool: æ˜¯å¦æˆåŠŸ
    """
    if not logs_data:
        return True

    session = SyncSessionLocal()

    try:
        # ä½¿ç”¨åŸç”Ÿ SQL æ‰¹æ¬¡æ’å…¥ï¼ˆæ•ˆèƒ½æœ€ä½³ï¼‰
        # åŸå§‹å¯«æ³•æœ‰èª¤ï¼šæ··ç”¨ :name å’Œ %(name)s åƒæ•¸æ ¼å¼
        # stmt = text("""
        #     INSERT INTO logs (device_id, log_level, message, log_data, created_at)
        #     VALUES (:device_id, :log_level, :message, :log_data::jsonb, :created_at)
        # """)
        stmt = text("""
            INSERT INTO logs (device_id, log_level, message, log_data, created_at)
            VALUES (:device_id, :log_level, :message, CAST(:log_data AS jsonb), :created_at)
        """)

        session.execute(stmt, logs_data)
        session.commit()

        print(f"âœ… æˆåŠŸå¯«å…¥ {len(logs_data)} ç­†æ—¥èªŒåˆ°è³‡æ–™åº«")
        return True

    except Exception as e:
        session.rollback()
        print(f"âŒ æ‰¹æ¬¡å¯«å…¥å¤±æ•—: {e}")
        return False

    finally:
        session.close()

# ==========================================
# è™•ç†è¨Šæ¯
# ==========================================
def process_messages(messages):
    """
    è™•ç†å¾ Redis Stream è®€å–çš„è¨Šæ¯

    åƒæ•¸ï¼š
        messages: Redis Stream è¨Šæ¯åˆ—è¡¨

    è¿”å›ï¼š
        tuple: (logs_to_insert, message_ids)
    """
    logs_to_insert = []
    message_ids = []

    for stream_name, stream_messages in messages:
        for message_id, message_data in stream_messages:
            try:
                # è§£ææ—¥èªŒè³‡æ–™
                log_data_str = message_data.get('log_data', '{}')

                # ç¢ºä¿ log_data æ˜¯å­—ä¸²æ ¼å¼
                if isinstance(log_data_str, dict):
                    log_data_str = json.dumps(log_data_str)

                # ä½¿ç”¨ Asia/Taipei æ™‚å€çš„ç•¶å‰æ™‚é–“ï¼Œä½†å¦‚æœæ¶ˆæ¯ä¸­å·²æœ‰æ™‚é–“æˆ³å‰‡å„ªå…ˆä½¿ç”¨
                timestamp_str = message_data.get('timestamp', datetime.now(ZoneInfo("Asia/Taipei")).isoformat())
                log_entry = {
                    'device_id': message_data['device_id'],
                    'log_level': message_data['log_level'],
                    'message': message_data['message'],
                    'log_data': log_data_str,
                    'created_at': timestamp_str
                }

                logs_to_insert.append(log_entry)
                message_ids.append(message_id)

            except Exception as e:
                print(f"âŒ è§£æè¨Šæ¯å¤±æ•— ({message_id}): {e}")
                # ä»ç„¶è¨˜éŒ„ message_idï¼Œä»¥ä¾¿ ACKï¼ˆé¿å…é‡è¤‡è™•ç†ï¼‰
                message_ids.append(message_id)

    return logs_to_insert, message_ids

# ==========================================
# ä¸»è¦å·¥ä½œå¾ªç’°
# ==========================================
def worker_loop():
    """
    Worker ä¸»è¦å·¥ä½œå¾ªç’°
    """
    global running

    print(f"ğŸš€ å•Ÿå‹• Worker: {WORKER_NAME}")
    print(f"ğŸ“Š è¨­å®š: æ‰¹æ¬¡å¤§å°={BATCH_SIZE}, é˜»å¡æ™‚é–“={BLOCK_MS}ms")
    print("-" * 60)

    error_count = 0
    max_errors = 10

    while running:
        try:
            # å¾ Redis Stream æ‰¹æ¬¡è®€å–è¨Šæ¯
            messages = redis_client.xreadgroup(
                groupname=GROUP_NAME,
                consumername=WORKER_NAME,
                streams={STREAM_NAME: '>'},
                count=BATCH_SIZE,
                block=BLOCK_MS
            )

            # æ²’æœ‰æ–°è¨Šæ¯
            if not messages:
                continue

            # è™•ç†è¨Šæ¯
            logs_to_insert, message_ids = process_messages(messages)

            if not logs_to_insert:
                print("âš ï¸ æ²’æœ‰æœ‰æ•ˆçš„æ—¥èªŒè³‡æ–™")
                continue

            # æ‰¹æ¬¡å¯«å…¥ PostgreSQL
            success = batch_insert_logs(logs_to_insert)

            if success:
                # ACK å·²è™•ç†çš„è¨Šæ¯
                for message_id in message_ids:
                    try:
                        redis_client.xack(STREAM_NAME, GROUP_NAME, message_id)
                    except Exception as e:
                        print(f"âŒ ACK å¤±æ•— ({message_id}): {e}")

                print(f"ğŸ“ è™•ç†å®Œæˆ: {len(logs_to_insert)} ç­†æ—¥èªŒ")
                error_count = 0  # é‡ç½®éŒ¯èª¤è¨ˆæ•¸
            else:
                error_count += 1
                print(f"âš ï¸ è™•ç†å¤±æ•—ï¼ŒéŒ¯èª¤æ¬¡æ•¸: {error_count}/{max_errors}")

                if error_count >= max_errors:
                    print(f"âŒ éŒ¯èª¤æ¬¡æ•¸éå¤šï¼Œåœæ­¢ Worker")
                    break

                # ç­‰å¾…å¾Œé‡è©¦
                time.sleep(5)

        except redis.exceptions.ConnectionError as e:
            print(f"âŒ Redis é€£ç·šéŒ¯èª¤: {e}")
            error_count += 1

            if error_count >= max_errors:
                print(f"âŒ é€£ç·šéŒ¯èª¤æ¬¡æ•¸éå¤šï¼Œåœæ­¢ Worker")
                break

            print(f"â³ 5ç§’å¾Œé‡æ–°é€£ç·š...")
            time.sleep(5)

            # å˜—è©¦é‡æ–°é€£ç·š
            if not init_redis():
                print("âŒ Redis é‡æ–°é€£ç·šå¤±æ•—")
                break

        except Exception as e:
            print(f"âŒ Worker ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
            error_count += 1

            if error_count >= max_errors:
                print(f"âŒ éŒ¯èª¤æ¬¡æ•¸éå¤šï¼Œåœæ­¢ Worker")
                break

            time.sleep(1)

# ==========================================
# æ¸…ç†è³‡æº
# ==========================================
def cleanup():
    """
    æ¸…ç†è³‡æº
    """
    global redis_client

    print("\nğŸ§¹ æ¸…ç†è³‡æº...")

    if redis_client:
        try:
            redis_client.close()
            print("âœ… Redis é€£ç·šå·²é—œé–‰")
        except Exception as e:
            print(f"âš ï¸ é—œé–‰ Redis é€£ç·šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    if sync_engine:
        try:
            sync_engine.dispose()
            print("âœ… è³‡æ–™åº«é€£ç·šæ± å·²é—œé–‰")
        except Exception as e:
            print(f"âš ï¸ é—œé–‰è³‡æ–™åº«é€£ç·šæ± æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# ==========================================
# ä¸»ç¨‹å¼å…¥å£
# ==========================================
def main():
    """
    ä¸»ç¨‹å¼å…¥å£
    """
    print("=" * 60)
    print("  ğŸ“¦ æ—¥èªŒæ”¶é›†ç³»çµ± - èƒŒæ™¯ Worker")
    print("=" * 60)

    # åˆå§‹åŒ– Redis
    if not init_redis():
        print("âŒ ç„¡æ³•å•Ÿå‹• Workerï¼ŒRedis é€£ç·šå¤±æ•—")
        sys.exit(1)

    # æ¸¬è©¦è³‡æ–™åº«é€£ç·š
    try:
        with sync_engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        print(f"âœ… PostgreSQL é€£ç·šæˆåŠŸ")
    except Exception as e:
        print(f"âŒ PostgreSQL é€£ç·šå¤±æ•—: {e}")
        sys.exit(1)

    print("-" * 60)

    try:
        # é–‹å§‹å·¥ä½œå¾ªç’°
        worker_loop()
    except KeyboardInterrupt:
        print("\nâš ï¸ æ¥æ”¶åˆ°éµç›¤ä¸­æ–·")
    finally:
        cleanup()
        print("ğŸ‘‹ Worker å·²åœæ­¢")

if __name__ == "__main__":
    main()
