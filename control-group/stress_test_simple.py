"""
å°ç…§çµ„å£“åŠ›æ¸¬è©¦è…³æœ¬ - æ¸¬è©¦ç°¡åŒ–ç‰ˆç³»çµ±
ç›´æ¥å¯«å…¥ PostgreSQLï¼Œç„¡è² è¼‰å¹³è¡¡ã€é€£æ¥æ± ã€Redisã€Worker
"""
import asyncio
import aiohttp
import time
import random
from datetime import datetime
from typing import List

# ==========================================
# æ¸¬è©¦é…ç½®
# ==========================================
BASE_URL = "http://localhost:18724"  # å°ç…§çµ„ç«¯é»
NUM_DEVICES = 100                    # è¨­å‚™æ•¸é‡
LOGS_PER_DEVICE = 100                # æ¯å°è¨­å‚™ç™¼é€çš„æ—¥èªŒæ•¸
CONCURRENT_LIMIT = 200               # ä¸¦ç™¼é™åˆ¶
BATCH_SIZE = 5                       # æ‰¹æ¬¡å¤§å°
USE_BATCH_API = True                 # æ˜¯å¦ä½¿ç”¨æ‰¹é‡ API
NUM_ITERATIONS = 20                 # æ¸¬è©¦åŸ·è¡Œçš„å¾ªç’°æ¬¡æ•¸
ITERATION_INTERVAL = 10               # æ¯æ¬¡å¾ªç’°ä¹‹é–“çš„é–“éš”æ™‚é–“ï¼ˆç§’ï¼‰

LOG_LEVELS = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
LOG_MESSAGES = [
    "ç³»çµ±æ­£å¸¸é‹è¡Œ",
    "è¨˜æ†¶é«”ä½¿ç”¨ç‡: {usage}%",
    "CPU æº«åº¦: {temp}Â°C",
    "ç¶²è·¯é€£ç·šç•°å¸¸",
    "è³‡æ–™åº«æŸ¥è©¢è¶…æ™‚",
    "æª”æ¡ˆè®€å–å¤±æ•—",
    "æ„Ÿæ¸¬å™¨è®€æ•¸ç•°å¸¸",
    "æ”å½±æ©Ÿç•«é¢æ¨¡ç³Š",
    "ç¡¬ç¢Ÿç©ºé–“ä¸è¶³",
    "è¨­å‚™é‡æ–°å•Ÿå‹•"
]

# ==========================================
# ç”Ÿæˆæ¸¬è©¦è³‡æ–™
# ==========================================
def generate_log_data(device_id: str, log_num: int) -> dict:
    """ç”Ÿæˆéš¨æ©Ÿæ—¥èªŒè³‡æ–™"""
    log_level = random.choice(LOG_LEVELS)
    message_template = random.choice(LOG_MESSAGES)

    if "{usage}" in message_template:
        message = message_template.format(usage=random.randint(50, 95))
    elif "{temp}" in message_template:
        message = message_template.format(temp=random.randint(40, 85))
    else:
        message = message_template

    return {
        "device_id": device_id,
        "log_level": log_level,
        "message": f"{message} (#{log_num})",
        "log_data": {
            "test_id": log_num,
            "timestamp": datetime.now().isoformat(),
            "random_value": random.random(),
            "sequence": log_num
        }
    }

# ==========================================
# ç™¼é€å–®ç­†æ—¥èªŒ
# ==========================================
async def send_log(session: aiohttp.ClientSession, device_id: str, log_num: int) -> dict:
    """ç™¼é€å–®ç­†æ—¥èªŒåˆ° API"""
    url = f"{BASE_URL}/api/log"
    log_data = generate_log_data(device_id, log_num)

    start_time = time.time()

    try:
        async with session.post(url, json=log_data, timeout=aiohttp.ClientTimeout(total=30)) as response:
            response_time = (time.time() - start_time) * 1000

            if response.status == 200:
                return {
                    "success": True,
                    "response_time": response_time,
                    "status": response.status,
                    "error": None,
                    "count": 1
                }
            else:
                return {
                    "success": False,
                    "response_time": response_time,
                    "status": response.status,
                    "error": await response.text(),
                    "count": 1
                }

    except asyncio.TimeoutError:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": "è«‹æ±‚è¶…æ™‚",
            "count": 1
        }
    except Exception as e:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": str(e),
            "count": 1
        }

# ==========================================
# ç™¼é€æ‰¹é‡æ—¥èªŒ
# ==========================================
async def send_batch_logs(session: aiohttp.ClientSession, logs: List[dict]) -> dict:
    """æ‰¹é‡ç™¼é€æ—¥èªŒåˆ° API"""
    url = f"{BASE_URL}/api/logs/batch"
    batch_data = {"logs": logs}

    start_time = time.time()

    try:
        async with session.post(url, json=batch_data, timeout=aiohttp.ClientTimeout(total=60)) as response:
            response_time = (time.time() - start_time) * 1000

            if response.status == 200:
                return {
                    "success": True,
                    "response_time": response_time,
                    "status": response.status,
                    "error": None,
                    "count": len(logs)
                }
            else:
                return {
                    "success": False,
                    "response_time": response_time,
                    "status": response.status,
                    "error": await response.text(),
                    "count": len(logs)
                }

    except asyncio.TimeoutError:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": "è«‹æ±‚è¶…æ™‚",
            "count": len(logs)
        }
    except Exception as e:
        return {
            "success": False,
            "response_time": (time.time() - start_time) * 1000,
            "status": 0,
            "error": str(e),
            "count": len(logs)
        }

# ==========================================
# æ‰¹æ¬¡ç™¼é€æ—¥èªŒ
# ==========================================
async def batch_send_logs(
    session: aiohttp.ClientSession,
    device_id: str,
    num_logs: int,
    semaphore: asyncio.Semaphore
) -> List[dict]:
    """æ‰¹æ¬¡ç™¼é€æ—¥èªŒï¼ˆä½¿ç”¨ä¿¡è™Ÿé‡æ§åˆ¶ä¸¦ç™¼ï¼‰"""
    if USE_BATCH_API:
        all_logs = [generate_log_data(device_id, log_num) for log_num in range(num_logs)]
        results = []

        for i in range(0, len(all_logs), BATCH_SIZE):
            batch = all_logs[i:i + BATCH_SIZE]
            async with semaphore:
                result = await send_batch_logs(session, batch)
                results.append(result)

        return results
    else:
        async def send_with_semaphore(log_num: int) -> dict:
            async with semaphore:
                return await send_log(session, device_id, log_num)

        tasks = [send_with_semaphore(log_num) for log_num in range(num_logs)]
        return await asyncio.gather(*tasks)

# ==========================================
# ä¸»è¦å£“åŠ›æ¸¬è©¦
# ==========================================
async def stress_test(
    num_devices: int = NUM_DEVICES,
    logs_per_device: int = LOGS_PER_DEVICE,
    concurrent_limit: int = CONCURRENT_LIMIT,
    iteration: int = 1,
    current_iteration: int = 1
):
    """åŸ·è¡Œå£“åŠ›æ¸¬è©¦"""
    print("=" * 70)
    if iteration > 1:
        print(f"  ğŸ“Š å°ç…§çµ„ - ç°¡åŒ–ç³»çµ±å£“åŠ›æ¸¬è©¦ [ç¬¬ {current_iteration}/{iteration} è¼ª]")
    else:
        print("  ğŸ“Š å°ç…§çµ„ - ç°¡åŒ–ç³»çµ±å£“åŠ›æ¸¬è©¦")
    print("=" * 70)
    print(f"æ¸¬è©¦é…ç½®ï¼š")
    print(f"  â€¢ è¨­å‚™æ•¸é‡: {num_devices}")
    print(f"  â€¢ æ¯å°è¨­å‚™æ—¥èªŒæ•¸: {logs_per_device}")
    print(f"  â€¢ ç¸½æ—¥èªŒæ•¸: {num_devices * logs_per_device:,}")
    print(f"  â€¢ ä¸¦ç™¼é™åˆ¶: {concurrent_limit}")
    print(f"  â€¢ API ç«¯é»: {BASE_URL}")
    print(f"  â€¢ ç³»çµ±ç‰¹æ€§: ç„¡ Nginxã€é€£æ¥æ± ã€Redisã€Worker")
    if iteration > 1:
        print(f"  â€¢ ç¸½å¾ªç’°æ¬¡æ•¸: {iteration}")
        print(f"  â€¢ ç•¶å‰å¾ªç’°: {current_iteration}")
    print("-" * 70)

    semaphore = asyncio.Semaphore(concurrent_limit)
    start_time = time.time()

    connector = aiohttp.TCPConnector(limit=concurrent_limit, limit_per_host=concurrent_limit)
    timeout = aiohttp.ClientTimeout(total=600)  # 10åˆ†é˜è¶…æ™‚ï¼ˆç°¡åŒ–ç‰ˆè¼ƒæ…¢ï¼‰

    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        device_tasks = []

        for device_num in range(num_devices):
            # ä¿®æ”¹ï¼šåŠ å…¥ 'control_' å‰ç¶´ä»¥å€åˆ†å°ç…§çµ„æ¸¬è©¦è³‡æ–™
            device_id = f"control_device_{device_num:03d}"
            task = batch_send_logs(session, device_id, logs_per_device, semaphore)
            device_tasks.append(task)

        print("â³ é–‹å§‹ç™¼é€æ—¥èªŒ...")
        all_results = await asyncio.gather(*device_tasks)

    total_time = time.time() - start_time

    # æ•´ç†çµæœ
    all_responses = [result for device_results in all_results for result in device_results]

    total_requests = len(all_responses)
    successful_requests = sum(1 for r in all_responses if r["success"])
    failed_requests = total_requests - successful_requests
    total_logs_sent = sum(r.get("count", 1) for r in all_responses)
    successful_logs = sum(r.get("count", 1) for r in all_responses if r["success"])

    response_times = [r["response_time"] for r in all_responses if r["success"]]

    if response_times:
        avg_response_time = sum(response_times) / len(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)

        sorted_times = sorted(response_times)
        p50 = sorted_times[int(len(sorted_times) * 0.50)]
        p95 = sorted_times[int(len(sorted_times) * 0.95)]
        p99 = sorted_times[int(len(sorted_times) * 0.99)]
    else:
        avg_response_time = 0
        min_response_time = 0
        max_response_time = 0
        p50 = p95 = p99 = 0

    throughput = successful_logs / total_time if total_time > 0 else 0

    # è¼¸å‡ºçµæœ
    print("\n" + "=" * 70)
    print("  ğŸ“ˆ æ¸¬è©¦çµæœ")
    print("=" * 70)

    print(f"\nâ±ï¸  æ™‚é–“çµ±è¨ˆï¼š")
    print(f"  â€¢ ç¸½è€—æ™‚: {total_time:.2f} ç§’")

    print(f"\nğŸ“Š è«‹æ±‚çµ±è¨ˆï¼š")
    if USE_BATCH_API:
        print(f"  â€¢ æ‰¹é‡è«‹æ±‚æ•¸: {total_requests:,}")
        print(f"  â€¢ ç¸½æ—¥èªŒæ•¸: {total_logs_sent:,}")
        print(f"  â€¢ æˆåŠŸæ—¥èªŒ: {successful_logs:,} ({successful_logs/total_logs_sent*100:.1f}%)")
    else:
        print(f"  â€¢ ç¸½è«‹æ±‚æ•¸: {total_requests:,}")
    print(f"  â€¢ æˆåŠŸè«‹æ±‚: {successful_requests:,} ({successful_requests/total_requests*100:.1f}%)")
    print(f"  â€¢ å¤±æ•—è«‹æ±‚: {failed_requests:,} ({failed_requests/total_requests*100:.1f}%)")

    print(f"\nâš¡ æ•ˆèƒ½æŒ‡æ¨™ï¼š")
    print(f"  â€¢ ååé‡: {throughput:.2f} logs/ç§’")
    print(f"  â€¢ å¹³å‡å›æ‡‰æ™‚é–“: {avg_response_time:.2f} ms")
    print(f"  â€¢ æœ€å°å›æ‡‰æ™‚é–“: {min_response_time:.2f} ms")
    print(f"  â€¢ æœ€å¤§å›æ‡‰æ™‚é–“: {max_response_time:.2f} ms")

    print(f"\nğŸ“‰ ç™¾åˆ†ä½æ•¸ï¼š")
    print(f"  â€¢ P50 (ä¸­ä½æ•¸): {p50:.2f} ms")
    print(f"  â€¢ P95: {p95:.2f} ms")
    print(f"  â€¢ P99: {p99:.2f} ms")

    if failed_requests > 0:
        print(f"\nâŒ éŒ¯èª¤åˆ†æï¼š")
        error_types = {}
        for r in all_responses:
            if not r["success"]:
                error = r["error"] or f"HTTP {r['status']}"
                error_types[error] = error_types.get(error, 0) + 1

        for error, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
            print(f"  â€¢ {error}: {count} æ¬¡")

    print("\n" + "=" * 70)

    target_throughput = 10000
    target_p95 = 100

    print(f"\nğŸ¯ ç›®æ¨™é”æˆæƒ…æ³ï¼š")

    if throughput >= target_throughput:
        print(f"  âœ… ååé‡é”æ¨™: {throughput:.2f} >= {target_throughput} logs/ç§’")
    else:
        print(f"  âŒ ååé‡æœªé”æ¨™: {throughput:.2f} < {target_throughput} logs/ç§’")

    if p95 <= target_p95:
        print(f"  âœ… P95 å›æ‡‰æ™‚é–“é”æ¨™: {p95:.2f} <= {target_p95} ms")
    else:
        print(f"  âŒ P95 å›æ‡‰æ™‚é–“æœªé”æ¨™: {p95:.2f} > {target_p95} ms")

    if failed_requests == 0:
        print(f"  âœ… ç„¡å¤±æ•—è«‹æ±‚")
    else:
        print(f"  âš ï¸ æœ‰ {failed_requests} å€‹å¤±æ•—è«‹æ±‚")

    print("=" * 70)

# ==========================================
# ä¸»ç¨‹å¼
# ==========================================
async def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    for i in range(NUM_ITERATIONS):
        await stress_test(
            num_devices=NUM_DEVICES,
            logs_per_device=LOGS_PER_DEVICE,
            concurrent_limit=CONCURRENT_LIMIT,
            iteration=NUM_ITERATIONS,
            current_iteration=i + 1
        )

        if i < NUM_ITERATIONS - 1 and ITERATION_INTERVAL > 0:
            print(f"\nâ¸ï¸  ç­‰å¾… {ITERATION_INTERVAL} ç§’å¾Œé–‹å§‹ä¸‹ä¸€è¼ªæ¸¬è©¦...")
            await asyncio.sleep(ITERATION_INTERVAL)

    print("\nâœ… æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())
